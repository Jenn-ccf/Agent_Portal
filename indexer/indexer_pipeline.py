import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config as config
import time
import json
from typing import Dict, Optional
from langchain_community.embeddings import HuggingFaceEmbeddings
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams
from utils.get_file_utils import get_folder_paths, process_all_folders
from utils.log_utils import get_processed_files, create_time_log_entry, log_to_file
from chunking import process_json_to_chunks
from utils.ocr_utils import convert_pdf_to_json
from utils.embedding_utils import EmbeddingProcessor


class Indexer:
    def __init__(self, embedding_processor, client):
        """
        åˆå§‹åŒ– Indexer é¡åˆ¥ï¼šå‘é‡è™•ç†å™¨ï¼‹Qdrant å®¢æˆ¶ç«¯
        """
        self.embedding_processor = embedding_processor
        try:
            self.client = client
        except Exception as e:
            print(f"å‘é‡è³‡æ–™åº«é€£ç·šç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            self.client = None

    def process_folder(self, folder_name: str) -> Optional[Dict[str, int]]:
        """
        è™•ç†å–®ä¸€è³‡æ–™å¤¾ä¸­çš„ PDF æª”æ¡ˆï¼š OCR -> Chunking -> Embedding -> Upsert
        """
        # å–å¾—è³‡æ–™å¤¾ç›¸é—œè·¯å¾‘
        paths = get_folder_paths(folder_name)
        pdf_directory = paths['pdf_directory']  # åŸå§‹ PDF è³‡æ–™å¤¾
        json_directory = paths['json_directory'] # OCR ç”¢ç”Ÿçš„ JSON è³‡æ–™å¤¾
        chunked_json_directory = paths['chunked_json_directory'] # Chunking ç”¢ç”Ÿçš„ JSON è³‡æ–™å¤¾
        indexer_ocr_log_directory = paths['indexer_ocr_log_directory'] # OCR æ—¥èªŒè³‡æ–™å¤¾
        indexer_chunk_log_directory = paths['indexer_chunk_log_directory'] # Chunking æ—¥èªŒè³‡æ–™å¤¾
        indexer_embed_log_directory = paths['indexer_embed_log_directory'] # Embedding+Upsert æ—¥èªŒè³‡æ–™å¤¾
        chunk_collection = paths['chunk_collection'] # Chunk å‘é‡é›†åˆåç¨±
        print(f"\nè™•ç†è³‡æ–™å¤¾: {pdf_directory}")
        
        # å»ºç«‹æˆ–é€£æ¥å‘é‡é›†åˆ
        if self.client is None:
            print("âŒ Qdrant é€£ç·šå¤±æ•—ï¼Œç„¡æ³•åŸ·è¡Œæµç¨‹ã€‚")
            return None 
        try: # å˜—è©¦é€£æ¥å·²å­˜åœ¨çš„é›†åˆ
            chunk_info = self.client.get_collection(chunk_collection)
            print(f"{chunk_collection} é›†åˆé€£æ¥æˆåŠŸï¼ŒåŒ…å« {chunk_info.points_count} æ¢è¨˜éŒ„")
        except Exception: # è‹¥ä¸å­˜åœ¨å‰‡å»ºç«‹æ–°é›†åˆ
            self.client.create_collection(
                collection_name=chunk_collection,
                vectors_config=VectorParams(
                    size=1024,
                    distance=Distance.COSINE
                )
            )
            print(f"å·²å‰µå»ºå‘é‡é›†åˆ: {chunk_collection} ")
        
        # ç¢ºä¿ JSON è³‡æ–™å¤¾å­˜åœ¨ï¼Œä¸å­˜åœ¨å³å»ºç«‹
        os.makedirs(json_directory, exist_ok=True)  
        # ç²å–è³‡æ–™å¤¾ä¸­ PDFæª”æ¡ˆåˆ—è¡¨
        if not os.path.exists(pdf_directory):
            print(f"PDFè³‡æ–™å¤¾ä¸å­˜åœ¨: {pdf_directory}")
            return
        pdf_files = [f for f in os.listdir(pdf_directory) if f.lower().endswith('.pdf')]
        if not pdf_files:
            print(f"åœ¨ {pdf_directory} ä¸­æ²’æœ‰æ‰¾åˆ°PDFæª”æ¡ˆ")
            return
        
        # ç²å–å·²è™•ç†éçš„æª”æ¡ˆåˆ—è¡¨
        processed_files = get_processed_files(indexer_ocr_log_directory + "/indexer_ocr.log")
        unprocessed_files = [f for f in pdf_files if f not in processed_files]
        if not unprocessed_files:
            print("æ‰€æœ‰PDFæª”æ¡ˆéƒ½å·²è™•ç†å®Œæˆ")
            return
        # é¡¯ç¤ºè™•ç†ç‹€æ³
        print(f"æ‰¾åˆ° {len(pdf_files)} å€‹PDFæª”æ¡ˆï¼Œå…¶ä¸­ {len(processed_files)} å€‹å·²è™•ç†")
        print(f"é–‹å§‹è™•ç†å‰©é¤˜çš„ {len(unprocessed_files)} å€‹æª”æ¡ˆ...")  
        
        # åˆå§‹åŒ–è¨ˆæ•¸å™¨
        ocr_success_count = 0
        ocr_failed_count = 0
        chunk_success_count = 0
        chunk_failed_count = 0
        embed_sucess_count = 0
        embed_failed_count = 0
        # === æµç¨‹ I & II & III: é€ä¸€æª”æ¡ˆé€²è¡Œ OCR -> Chunking -> Embedding & Upsert ===
        for i, pdf_file in enumerate(unprocessed_files, 1):
            pdf_path =  os.path.join(pdf_directory, pdf_file)
            json_filename = os.path.splitext(pdf_file)[0] + '.json'
            json_path = os.path.join(json_directory, json_filename)
            chunked_filename = f"chunked_{json_filename}"
            chunked_json = os.path.join(chunked_json_directory, chunked_filename)
            print(f"[{i}/{len(unprocessed_files)}] è™•ç†: {pdf_file}")
            
            # --- éšæ®µ I: OCR (PDF -> JSON) ---
            ocr_start = time.time()
            # å‘¼å« convert_pdf_to_json é€²è¡Œ OCR 
            ocr_success = convert_pdf_to_json(pdf_path, json_path)
            description = "PDF è½‰æ›ç‚º OCR JSON"
            if not ocr_success:
                ocr_failed_count += 1
                log_entry = create_time_log_entry(pdf_file, f"{description}ï½œç‹€æ…‹ï¼šå¤±æ•—", ocr_start)
                log_to_file(log_entry, os.path.join(indexer_ocr_log_directory, "indexer_ocr.log"))
                print(f" âŒ OCR å¤±æ•— (è·³échunking+å‘é‡åŒ–): {pdf_file}")  
                continue # è·³éå¾ŒçºŒçš„ Chunking+Embedding æ­¥é©Ÿ
            ocr_success_count += 1
            log_entry = create_time_log_entry(pdf_file, f"{description}ï½œç‹€æ…‹ï¼šæˆåŠŸ", ocr_start)
            log_to_file(log_entry, os.path.join(indexer_ocr_log_directory, "indexer_ocr.log"))
            print(f" âœ… æˆåŠŸ OCR: {json_filename}") 

            # --- éšæ®µ II: Chunking (JSON -> chunked JSON) ---
            chunk_start = time.time()
            # å‘¼å« process_json_to_chunks é€²è¡Œ chunking
            chunk_success= process_json_to_chunks(input_json_path = json_path, output_json_path = chunked_json)
            description = "JSON è½‰æ›ç‚º Chunked JSON"
            if not chunk_success:
                chunk_failed_count += 1
                log_entry = create_time_log_entry(json_filename, f"{description}ï½œç‹€æ…‹ï¼šå¤±æ•—", chunk_start)
                log_to_file(log_entry, os.path.join(indexer_chunk_log_directory, "indexer_chunk.log"))
                print(f" âŒ Chunking å¤±æ•— (è·³éå‘é‡åŒ–): {pdf_file}")  
                continue # è·³éå¾ŒçºŒçš„ Embedding æ­¥é©Ÿ
            chunk_success_count += 1
            log_entry = create_time_log_entry(json_filename, f"{description}ï½œç‹€æ…‹ï¼šæˆåŠŸ", chunk_start)
            log_to_file(log_entry, os.path.join(indexer_chunk_log_directory, "indexer_chunk.log"))
            print(f" âœ… æˆåŠŸ Chunking: {json_filename}") 

            # --- éšæ®µ III: Embedding & Upsert (chunked JSON -> Qdrant) ---
            try:
                with open(chunked_json, "r", encoding="utf-8") as f:
                    data = json.load(f)
                chunks = list(data.values())
                # å‘¼å« chunk_embedding_upsert é€²è¡Œ embedding + upsert
                embed_success = self.embedding_processor.chunk_embedding_upsert(chunks, json_filename, chunk_collection, indexer_embed_log_directory)
                if embed_success:
                    embed_sucess_count += 1
                    print(f"âœ… æˆåŠŸå‘é‡åŒ–ä¸¦å„²å­˜: {json_filename}")
                else:
                    embed_failed_count += 1
                    print(f" âŒ å‘é‡åŒ–å„²å­˜å¤±æ•—: {json_filename}")
            except Exception as e:
                embed_failed_count += 1
                print(f" âŒ è®€å–æˆ–å‘é‡åŒ–æ™‚ç™¼ç”ŸéŒ¯èª¤: {json_filename}, Error: {str(e)}")
        
        # === æœ€çµ‚çµ±è¨ˆ ===
        print("\nğŸ“Š è™•ç†çµæœç¸½çµ:")
        print(f" éšæ®µ I (OCR) æˆåŠŸ/å¤±æ•—: {ocr_success_count}/{ocr_failed_count}")
        print(f" éšæ®µ II (Chunking) æˆåŠŸ/å¤±æ•—: {chunk_success_count}/{chunk_failed_count}")
        print(f" éšæ®µ III (Embedding+Upsert) æˆåŠŸ/å¤±æ•—: {embed_sucess_count}/{embed_failed_count}")
        return {
            "ocr_success": ocr_success_count,
            "ocr_failed": ocr_failed_count,
            "chunk_success": chunk_success_count,
            "chunk_failed": chunk_failed_count,
            "embed_success": embed_sucess_count,
            "embed_failed": embed_failed_count
        }  
     
def main():
    """
    ä¸»ç¨‹å¼å…¥å£ï¼šé€£æ¥ Qdrantï¼Œè¼‰å…¥æ¨¡å‹ï¼Œè™•ç†æ‰€æœ‰è³‡æ–™å¤¾
    """
    print("ğŸ”„ é€£æ¥ Qdrant å‘é‡è³‡æ–™åº«...")
    qdrant_client = QdrantClient(path=config.PERSIST_DIRECTORY) # ä½¿ç”¨æœ¬åœ°æª”æ¡ˆå­˜å–æ¨¡å¼
    # qdrant_client = QdrantClient(host=config.QDRANT_HOST, port=config.QDRANT_PORT) # ä½¿ç”¨ç¶²è·¯å­˜å–æ¨¡å¼
    print("âœ… Qdrant é€£æ¥æˆåŠŸï¼")
    print("ğŸ”„ BGE-M3 æ¨¡å‹è¼‰å…¥...")
    embedding_model = HuggingFaceEmbeddings(
                model_name=config.MODEL_NAME,
                model_kwargs=config.MODEL_KWARGS
            )
    print("âœ… BGE-M3 æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    embedding_processor = EmbeddingProcessor(embedding_model=embedding_model, client=qdrant_client)
    indexer = Indexer(embedding_processor=embedding_processor, client=qdrant_client)
    process_all_folders(indexer.process_folder)

if __name__ == "__main__":
    main()