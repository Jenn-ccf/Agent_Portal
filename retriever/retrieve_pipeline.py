from typing import List, Dict, Union, Any
from langchain_community.embeddings import HuggingFaceEmbeddings
import datetime
datetime = datetime.datetime
from search import VectorSearch
from rerank import Rerank
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config as config

# =======================
# æª¢ç´¢å™¨
# =======================
class Retriever:
    def __init__(self, search_tool, rerank_tool):
        """åˆå§‹åŒ–æª¢ç´¢å™¨ï¼Œæ³¨å…¥ä¾è³´çš„å·¥å…·å¯¦ä¾‹"""
        self.searcher = search_tool
        self.reranker = rerank_tool
    
    def _process_search_results(self, search_type: str, search_result: List[Any]) -> List[Dict[str, Any]]:
        """è™•ç†æœå°‹çµæœï¼Œåˆ†æˆchunkèˆ‡summaryå…©ç¨®æ ¼å¼"""
        results = []
        if search_type == "chunk":
            for point in search_result:
                result = {
                    'similarity_score': point.score,
                    'filename': point.payload.get('filename', ''),
                    'page': point.payload.get('page', ''),
                    'content_preview': point.payload.get('content', '')[:200] + "..." if len(point.payload.get('content', '')) > 200 else point.payload.get('content', ''),
                    'full_content': point.payload.get('content', '')
                }
                results.append(result)
        else:  # summary
            for point in search_result:
                result = {
                    'similarity_score': point.score,
                    'filename': point.payload.get('filename', ''),
                    'title': point.payload.get('title', ''),
                    'file_type': point.payload.get('file_type'),
                    'metadata': point.payload.get('metadata', []),
                    'summary': point.payload.get('summary', '')
                }
                results.append(result)        
        return results  
    
    async def retrieve(self, query: str, threshold_score: float, top_k: int, collection: str, search_type: str, categories: List[str] = None) -> Dict[str, Union[List[Any], int]]:
        """ä¸»è¦æª¢ç´¢æµç¨‹"""
        # åŸ·è¡Œå‘é‡æœå°‹
        query_vector, search_result = await self.searcher.search(query, top_k, search_type, collection, categories)
        # è™•ç†æœå°‹çµæœ
        results = self._process_search_results(search_type, search_result)
        print(f"ğŸ“Š Search å¾Œï¼Œç›¸ä¼¼åº¦åˆ†æ•¸ç¯„åœ: {min(r['similarity_score'] for r in results):.4f} - {max(r['similarity_score'] for r in results):.4f}")
        # æ ¹æ“šæœå°‹é¡å‹é€²è¡Œå¾Œè™•ç†
        # summary -> é‡æ’åº
        if search_type == "summary":
            reranked_output = await self.reranker.rerank_by_title(query_vector, results)
            filtered_reranked = [res for res in reranked_output if res['title_similarity'] >= threshold_score]
            return {
                "results": filtered_reranked,
                "total_count": len(filtered_reranked)   
            } 
        else: # chunk -> ç›´æ¥éæ¿¾
            filtered_results = [res for res in results if res['similarity_score'] >= threshold_score]
            return {
                "results": filtered_results, 
                "total_count": len(filtered_results)
            }


# =======================
# æ¸¬è©¦ç¨‹å¼
# =======================
if __name__ == "__main__":
    # æ¨¡å‹è¼‰å…¥
    print("ğŸ”„ é–‹å§‹è¼‰å…¥ BGE-M3 æ¨¡å‹...")
    EMBEDDING_MODEL = HuggingFaceEmbeddings(
                model_name=config.MODEL_NAME,
                model_kwargs=config.MODEL_KWARGS
            )
    print("âœ… BGE-M3 æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    
    # å¯¦ä¾‹åŒ– searcher & reranker
    search_tool = VectorSearch(embedding_model=EMBEDDING_MODEL)
    rerank_tool = Rerank(embedding_model=EMBEDDING_MODEL)
    retriever = Retriever(search_tool=search_tool, rerank_tool=rerank_tool)
    
    # åŸ·è¡Œæª¢ç´¢æ¸¬è©¦
    search_type = "summary"  
    # search_type = "chunk"
    collection = "form"
    test_query = "ç™Œç—‡ä¿éšª ç–¾ç—…ç­‰å¾…æœŸé–“"
    
    import asyncio
    resultDICT = asyncio.run(
        retriever.retrieve(
            query=test_query,
            threshold_score=config.THRESHOLD_SCORE,
            top_k=config.TOP_K,
            collection=collection,
            search_type=search_type
        )
    )
    print(f"ğŸ“æœå°‹æ–¹å¼ï¼š{search_type}ï½œå›å‚³ {resultDICT['total_count']} ç­†çµæœ")
    